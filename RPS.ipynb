{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow import keras\n",
    "import keras\n",
    "import numpy as np\n",
    "import itertools\n",
    "from random import randint\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# wget https://github.com/PizzaRollExpert/Rock-paper-scissors-data/raw/master/data.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a92d11f875cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#s represents rock, x scissors, p paper and - the end of a game.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#player is 1st move, algorithm 2nd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.txt'"
     ]
    }
   ],
   "source": [
    "data = open('data.txt').read()\n",
    "data = data.split('\\n')\n",
    "\n",
    "#s represents rock, x scissors, p paper and - the end of a game.\n",
    "#player is 1st move, algorithm 2nd\n",
    "n_to_move = {\n",
    "  1:'s',\n",
    "  2:'p',\n",
    "  3:'x'\n",
    "}\n",
    "\n",
    "full_n_to_move = {\n",
    "  1:'rock',\n",
    "  2:'paper',\n",
    "  3:'scissors'\n",
    "}\n",
    "\n",
    "move_to_n = {\n",
    "    's':1,\n",
    "    'p':2,\n",
    "    'x':3\n",
    "}\n",
    "\n",
    "\n",
    "def convert_data(data):\n",
    "    result = []\n",
    "    game = []\n",
    "    for row in data:\n",
    "        moves = []\n",
    "        if row == '-':\n",
    "            if len(game) > 2:\n",
    "                result.append(np.array(game))\n",
    "                game = []\n",
    "            continue\n",
    "        for move in row:\n",
    "            moves.append(move_to_n[move])\n",
    "        if len(moves) > 1:\n",
    "            game.append(np.array(moves))\n",
    "        moves = []\n",
    "    return np.array(result)\n",
    "\n",
    "data = convert_data(data)\n",
    "data2 = np.array([np.flip(games, 1) for games in data]) #reverse for player2\n",
    "data = np.concatenate((data2, data))\n",
    "\n",
    "def calculate_winner(x):\n",
    "    result = x[0] - x[1]\n",
    "    if result == 0: return 0 #tie\n",
    "    if result in (1,-2): return 1 #win\n",
    "    return -1 #lose\n",
    "\n",
    "def create_xy_winner(data):\n",
    "    result_y = []\n",
    "    result_x = []\n",
    "    for game in data:\n",
    "        game_y = []\n",
    "        score = 0\n",
    "        for i, moves in enumerate(game):\n",
    "            if i+1 == len(game):\n",
    "                result_y.append(np.array(game_y))\n",
    "                result_x.append(game[:-1]) #remove last moves from x\n",
    "                #skip last game as we dont know what player1 will choose next move\n",
    "                continue\n",
    "            score += calculate_winner(game[i])\n",
    "            game_y.append([game[i+1][0], score]) #append next player1 move\n",
    "    return np.array(result_x), np.array(result_y)\n",
    "\n",
    "X_gh, y_gh = create_xy_winner(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN THIS TO TRAIN ON COLLECTED DATA\n",
    "\n",
    "collected_data = open('collected-data.txt').read().split('\\n')\n",
    "collected_parsed = [json.loads(row) for row in collected_data[:-1]]\n",
    "collected_data = []\n",
    "user_games = {}\n",
    "for i in range(len(collected_parsed)):\n",
    "    user_games[collected_parsed[i][0]] = collected_parsed[i][1]\n",
    "for collected in user_games.values():\n",
    "    split_games = [collected[x:x+30] for x in range(0, len(user_games), 28) if (len(collected) - x > 5)]\n",
    "    for games in split_games:\n",
    "        collected_data.append(np.array([[np.argmax(game[:4]), np.argmax(game[4:])] for game in games]))\n",
    "\n",
    "collected_data = np.array(collected_data)\n",
    "\n",
    "X_col, y_col = create_xy_winner(collected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None, 8)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, None, 32)     288         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, None, 96)     49536       dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, None, 20)     1940        lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, None, 20)     1940        lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, None, 4)      84          dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, None, 1)      21          dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 53,809\n",
      "Trainable params: 53,809\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "main_input = keras.Input(shape=(None,8), dtype='float32')\n",
    "dense = keras.layers.Dense(32, activation='relu')(main_input)\n",
    "lstm = keras.layers.LSTM(96, return_sequences=True)(dense)\n",
    "main_output = keras.layers.Dense(20, activation='relu')(lstm)\n",
    "main_output = keras.layers.Dense(4, activation='softmax')(main_output)\n",
    "second_output = keras.layers.Dense(20, activation='tanh')(lstm)\n",
    "second_output = keras.layers.Dense(1)(second_output)\n",
    "model = keras.Model(inputs=[main_input,], outputs=[main_output, second_output])\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss=['categorical_crossentropy', 'mse'], optimizer=opt, metrics=['accuracy'], loss_weights=[1., 0.1])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**0.001**\n",
      "\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.6223 - dense_8_loss: 1.3738 - dense_10_loss: 2.4852 - dense_8_acc: 0.3333 - dense_10_acc: 0.2222\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.9604 - dense_8_loss: 1.3541 - dense_10_loss: 6.0638 - dense_8_acc: 0.3333 - dense_10_acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      " - 0s - loss: 3.4683 - dense_8_loss: 1.5834 - dense_10_loss: 18.8486 - dense_8_acc: 0.2632 - dense_10_acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.4165 - dense_8_loss: 1.2081 - dense_10_loss: 2.0847 - dense_8_acc: 0.6667 - dense_10_acc: 0.1667\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.4048 - dense_8_loss: 1.1640 - dense_10_loss: 2.4083 - dense_8_acc: 0.5185 - dense_10_acc: 0.2222\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.4434 - dense_8_loss: 1.2005 - dense_10_loss: 12.4294 - dense_8_acc: 0.4483 - dense_10_acc: 0.0345\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.3356 - dense_8_loss: 0.6226 - dense_10_loss: 7.1301 - dense_8_acc: 0.7857 - dense_10_acc: 0.2143\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.0448 - dense_8_loss: 1.0985 - dense_10_loss: 9.4634 - dense_8_acc: 0.3333 - dense_10_acc: 0.0667\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.5281 - dense_8_loss: 1.2460 - dense_10_loss: 2.8214 - dense_8_acc: 0.3333 - dense_10_acc: 0.1333\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.4052 - dense_8_loss: 1.2821 - dense_10_loss: 1.2309 - dense_8_acc: 0.2069 - dense_10_acc: 0.2759\n",
      "**0.0008**\n",
      "\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.3260 - dense_8_loss: 1.2773 - dense_10_loss: 0.4877 - dense_8_acc: 0.2000 - dense_10_acc: 0.6000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2337 - dense_8_loss: 1.2092 - dense_10_loss: 0.2449 - dense_8_acc: 0.0000e+00 - dense_10_acc: 0.6667\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.3049 - dense_8_loss: 1.1697 - dense_10_loss: 1.3522 - dense_8_acc: 0.6667 - dense_10_acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.3085 - dense_8_loss: 1.2194 - dense_10_loss: 0.8909 - dense_8_acc: 0.1667 - dense_10_acc: 0.3333\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.3689 - dense_8_loss: 1.1419 - dense_10_loss: 2.2698 - dense_8_acc: 0.5000 - dense_10_acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2505 - dense_8_loss: 1.1492 - dense_10_loss: 1.0125 - dense_8_acc: 0.2500 - dense_10_acc: 0.5000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.3138 - dense_8_loss: 1.1555 - dense_10_loss: 1.5831 - dense_8_acc: 0.1667 - dense_10_acc: 0.3333\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.3145 - dense_8_loss: 1.1717 - dense_10_loss: 1.4281 - dense_8_acc: 0.0000e+00 - dense_10_acc: 0.3333\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1558 - dense_8_loss: 1.1080 - dense_10_loss: 0.4780 - dense_8_acc: 0.5000 - dense_10_acc: 0.5000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1868 - dense_8_loss: 1.1339 - dense_10_loss: 0.5287 - dense_8_acc: 0.4000 - dense_10_acc: 0.6000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2450 - dense_8_loss: 1.1402 - dense_10_loss: 1.0483 - dense_8_acc: 0.3333 - dense_10_acc: 0.3333\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1343 - dense_8_loss: 1.0861 - dense_10_loss: 0.4813 - dense_8_acc: 0.6667 - dense_10_acc: 0.5000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1851 - dense_8_loss: 1.0864 - dense_10_loss: 0.9865 - dense_8_acc: 0.3636 - dense_10_acc: 0.1818\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.3142 - dense_8_loss: 1.1077 - dense_10_loss: 2.0651 - dense_8_acc: 0.6667 - dense_10_acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2629 - dense_8_loss: 1.0671 - dense_10_loss: 1.9587 - dense_8_acc: 0.6667 - dense_10_acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2733 - dense_8_loss: 1.1048 - dense_10_loss: 1.6854 - dense_8_acc: 0.3750 - dense_10_acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2030 - dense_8_loss: 1.0916 - dense_10_loss: 1.1140 - dense_8_acc: 0.3333 - dense_10_acc: 0.3333\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1880 - dense_8_loss: 1.1661 - dense_10_loss: 0.2189 - dense_8_acc: 0.0000e+00 - dense_10_acc: 0.6000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2934 - dense_8_loss: 1.0412 - dense_10_loss: 2.5221 - dense_8_acc: 0.5000 - dense_10_acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2068 - dense_8_loss: 1.0857 - dense_10_loss: 1.2110 - dense_8_acc: 0.5000 - dense_10_acc: 0.5000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.3434 - dense_8_loss: 1.1828 - dense_10_loss: 1.6060 - dense_8_acc: 0.2000 - dense_10_acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1083 - dense_8_loss: 1.0609 - dense_10_loss: 0.4739 - dense_8_acc: 0.5000 - dense_10_acc: 0.2500\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1380 - dense_8_loss: 1.0508 - dense_10_loss: 0.8718 - dense_8_acc: 0.6000 - dense_10_acc: 0.4000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2531 - dense_8_loss: 1.0561 - dense_10_loss: 1.9704 - dense_8_acc: 0.4000 - dense_10_acc: 0.4000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0766 - dense_8_loss: 1.0408 - dense_10_loss: 0.3574 - dense_8_acc: 0.5000 - dense_10_acc: 0.6667\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.3537 - dense_8_loss: 1.1088 - dense_10_loss: 2.4494 - dense_8_acc: 0.4444 - dense_10_acc: 0.4444\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1159 - dense_8_loss: 1.0629 - dense_10_loss: 0.5301 - dense_8_acc: 0.3333 - dense_10_acc: 0.3333\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9944 - dense_8_loss: 0.9507 - dense_10_loss: 0.4369 - dense_8_acc: 1.0000 - dense_10_acc: 0.3333\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2513 - dense_8_loss: 1.1934 - dense_10_loss: 0.5790 - dense_8_acc: 0.0000e+00 - dense_10_acc: 0.5000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2491 - dense_8_loss: 1.1757 - dense_10_loss: 0.7336 - dense_8_acc: 0.0000e+00 - dense_10_acc: 0.2000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1575 - dense_8_loss: 1.0579 - dense_10_loss: 0.9960 - dense_8_acc: 0.5000 - dense_10_acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1484 - dense_8_loss: 1.0768 - dense_10_loss: 0.7164 - dense_8_acc: 0.3750 - dense_10_acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1820 - dense_8_loss: 1.1265 - dense_10_loss: 0.5556 - dense_8_acc: 0.1111 - dense_10_acc: 0.2222\n",
      "**0.0007**\n",
      "\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2776 - dense_8_loss: 1.1882 - dense_10_loss: 0.8943 - dense_8_acc: 0.1111 - dense_10_acc: 0.3333\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.1204 - dense_8_loss: 1.2543 - dense_10_loss: 8.6606 - dense_8_acc: 0.1667 - dense_10_acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.6917 - dense_8_loss: 1.3118 - dense_10_loss: 13.7994 - dense_8_acc: 0.2632 - dense_10_acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1224 - dense_8_loss: 1.0989 - dense_10_loss: 0.2353 - dense_8_acc: 0.1667 - dense_10_acc: 0.8333\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0642 - dense_8_loss: 1.0288 - dense_10_loss: 0.3543 - dense_8_acc: 0.4815 - dense_10_acc: 0.5556\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.8873 - dense_8_loss: 1.5839 - dense_10_loss: 3.0341 - dense_8_acc: 0.4483 - dense_10_acc: 0.3793\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7899 - dense_8_loss: 0.4878 - dense_10_loss: 3.0207 - dense_8_acc: 0.8571 - dense_10_acc: 0.3571\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2457 - dense_8_loss: 1.0667 - dense_10_loss: 1.7906 - dense_8_acc: 0.4000 - dense_10_acc: 0.2667\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.3107 - dense_8_loss: 1.1048 - dense_10_loss: 2.0588 - dense_8_acc: 0.4000 - dense_10_acc: 0.6000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 3.6147 - dense_8_loss: 1.2496 - dense_10_loss: 23.6513 - dense_8_acc: 0.4483 - dense_10_acc: 0.0345\n",
      "**5e-05**\n",
      "\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1383 - dense_8_loss: 1.1289 - dense_10_loss: 0.0942 - dense_8_acc: 0.4000 - dense_10_acc: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2566 - dense_8_loss: 1.1835 - dense_10_loss: 0.7312 - dense_8_acc: 0.0000e+00 - dense_10_acc: 0.3333\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0732 - dense_8_loss: 1.0263 - dense_10_loss: 0.4691 - dense_8_acc: 0.6667 - dense_10_acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1949 - dense_8_loss: 1.1724 - dense_10_loss: 0.2250 - dense_8_acc: 0.1667 - dense_10_acc: 0.6667\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1933 - dense_8_loss: 1.0852 - dense_10_loss: 1.0807 - dense_8_acc: 0.5000 - dense_10_acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1494 - dense_8_loss: 1.1128 - dense_10_loss: 0.3661 - dense_8_acc: 0.2500 - dense_10_acc: 0.7500\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1743 - dense_8_loss: 1.1421 - dense_10_loss: 0.3219 - dense_8_acc: 0.1667 - dense_10_acc: 0.5000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1189 - dense_8_loss: 1.1170 - dense_10_loss: 0.0191 - dense_8_acc: 0.3333 - dense_10_acc: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0875 - dense_8_loss: 1.0788 - dense_10_loss: 0.0877 - dense_8_acc: 0.2500 - dense_10_acc: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1291 - dense_8_loss: 1.1197 - dense_10_loss: 0.0938 - dense_8_acc: 0.4000 - dense_10_acc: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1182 - dense_8_loss: 1.1178 - dense_10_loss: 0.0036 - dense_8_acc: 0.0000e+00 - dense_10_acc: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0948 - dense_8_loss: 1.0896 - dense_10_loss: 0.0515 - dense_8_acc: 0.1667 - dense_10_acc: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0938 - dense_8_loss: 1.0441 - dense_10_loss: 0.4976 - dense_8_acc: 0.3636 - dense_10_acc: 0.5455\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1132 - dense_8_loss: 1.0892 - dense_10_loss: 0.2396 - dense_8_acc: 0.3333 - dense_10_acc: 0.6667\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0768 - dense_8_loss: 1.0565 - dense_10_loss: 0.2022 - dense_8_acc: 0.6667 - dense_10_acc: 0.6667\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1794 - dense_8_loss: 1.1343 - dense_10_loss: 0.4507 - dense_8_acc: 0.2500 - dense_10_acc: 0.5000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1178 - dense_8_loss: 1.0956 - dense_10_loss: 0.2222 - dense_8_acc: 0.3333 - dense_10_acc: 0.3333\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1424 - dense_8_loss: 1.1394 - dense_10_loss: 0.0297 - dense_8_acc: 0.0000e+00 - dense_10_acc: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0269 - dense_8_loss: 0.9735 - dense_10_loss: 0.5335 - dense_8_acc: 0.5000 - dense_10_acc: 0.2500\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0881 - dense_8_loss: 1.0823 - dense_10_loss: 0.0586 - dense_8_acc: 0.5000 - dense_10_acc: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1082 - dense_8_loss: 1.1079 - dense_10_loss: 0.0029 - dense_8_acc: 0.2000 - dense_10_acc: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0363 - dense_8_loss: 1.0359 - dense_10_loss: 0.0036 - dense_8_acc: 0.5000 - dense_10_acc: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0613 - dense_8_loss: 1.0561 - dense_10_loss: 0.0519 - dense_8_acc: 0.6000 - dense_10_acc: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9860 - dense_8_loss: 0.9801 - dense_10_loss: 0.0592 - dense_8_acc: 0.8000 - dense_10_acc: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0223 - dense_8_loss: 1.0195 - dense_10_loss: 0.0280 - dense_8_acc: 0.5000 - dense_10_acc: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0701 - dense_8_loss: 1.0675 - dense_10_loss: 0.0266 - dense_8_acc: 0.4444 - dense_10_acc: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0481 - dense_8_loss: 1.0346 - dense_10_loss: 0.1348 - dense_8_acc: 0.3333 - dense_10_acc: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9318 - dense_8_loss: 0.9207 - dense_10_loss: 0.1109 - dense_8_acc: 0.6667 - dense_10_acc: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1478 - dense_8_loss: 1.1451 - dense_10_loss: 0.0277 - dense_8_acc: 0.0000e+00 - dense_10_acc: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1393 - dense_8_loss: 1.1376 - dense_10_loss: 0.0167 - dense_8_acc: 0.2000 - dense_10_acc: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0136 - dense_8_loss: 1.0105 - dense_10_loss: 0.0312 - dense_8_acc: 0.5000 - dense_10_acc: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0651 - dense_8_loss: 1.0528 - dense_10_loss: 0.1237 - dense_8_acc: 0.3750 - dense_10_acc: 0.8750\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0915 - dense_8_loss: 1.0678 - dense_10_loss: 0.2371 - dense_8_acc: 0.1111 - dense_10_acc: 0.4444\n",
      "**0.0001**\n",
      "\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1750 - dense_8_loss: 1.1437 - dense_10_loss: 0.3131 - dense_8_acc: 0.2222 - dense_10_acc: 0.4444\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1251 - dense_8_loss: 1.1085 - dense_10_loss: 0.1663 - dense_8_acc: 0.3333 - dense_10_acc: 0.6667\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1288 - dense_8_loss: 1.0958 - dense_10_loss: 0.3300 - dense_8_acc: 0.3158 - dense_10_acc: 0.5789\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0128 - dense_8_loss: 0.9959 - dense_10_loss: 0.1690 - dense_8_acc: 0.6667 - dense_10_acc: 0.6667\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.5452 - dense_8_loss: 1.0291 - dense_10_loss: 5.1608 - dense_8_acc: 0.5185 - dense_10_acc: 0.0741\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.6201 - dense_8_loss: 1.3893 - dense_10_loss: 2.3086 - dense_8_acc: 0.6207 - dense_10_acc: 0.3448\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0917 - dense_8_loss: 0.6353 - dense_10_loss: 4.5643 - dense_8_acc: 0.8571 - dense_10_acc: 0.0714\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1098 - dense_8_loss: 1.1054 - dense_10_loss: 0.0445 - dense_8_acc: 0.3333 - dense_10_acc: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1331 - dense_8_loss: 1.0986 - dense_10_loss: 0.3449 - dense_8_acc: 0.4000 - dense_10_acc: 0.4667\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1951 - dense_8_loss: 1.1433 - dense_10_loss: 0.5184 - dense_8_acc: 0.2759 - dense_10_acc: 0.3793\n",
      "**1e-05**\n",
      "\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2211 - dense_8_loss: 1.0405 - dense_10_loss: 1.8060 - dense_8_acc: 0.3333 - dense_10_acc: 0.2222\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1216 - dense_8_loss: 1.0903 - dense_10_loss: 0.3127 - dense_8_acc: 0.5000 - dense_10_acc: 0.6667\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.5497 - dense_8_loss: 1.1033 - dense_10_loss: 4.4640 - dense_8_acc: 0.2632 - dense_10_acc: 0.1053\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9854 - dense_8_loss: 0.9771 - dense_10_loss: 0.0823 - dense_8_acc: 0.6667 - dense_10_acc: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0161 - dense_8_loss: 0.9840 - dense_10_loss: 0.3210 - dense_8_acc: 0.5556 - dense_10_acc: 0.5185\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2952 - dense_8_loss: 1.1479 - dense_10_loss: 1.4729 - dense_8_acc: 0.4828 - dense_10_acc: 0.3793\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6380 - dense_8_loss: 0.4823 - dense_10_loss: 1.5571 - dense_8_acc: 0.8571 - dense_10_acc: 0.3571\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2353 - dense_8_loss: 1.1103 - dense_10_loss: 1.2502 - dense_8_acc: 0.4667 - dense_10_acc: 0.0667\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0794 - dense_8_loss: 1.0612 - dense_10_loss: 0.1818 - dense_8_acc: 0.5333 - dense_10_acc: 0.8000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.3716 - dense_8_loss: 1.0911 - dense_10_loss: 2.8052 - dense_8_acc: 0.3103 - dense_10_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "#MODEL FIT\n",
    "\n",
    "for (X, y, lr) in [(X_col, y_col, 0.001), (X_gh, y_gh, 0.0008), (X_col, y_col, 0.0007), (X_gh, y_gh, 0.00005), (X_col, y_col, 0.0001), (X_col, y_col, 0.00001)]:\n",
    "    ## Anneal learning late\n",
    "    model.optimizer.lr.assign(lr)\n",
    "    print(f'**{lr}**\\n')\n",
    "    batch_x = []\n",
    "    batch_y = []\n",
    "    for i in range(len(X)):\n",
    "        X_, y_ = X[i], y[i]\n",
    "        X_ = keras.utils.to_categorical(X_, 4)\n",
    "        X_ = X_.reshape(1, X_.shape[0], 8)\n",
    "        y_1 = keras.utils.to_categorical(y_[:,0].reshape(1, y_.shape[0], 1), 4)\n",
    "        y_2 = y_[:,1].reshape(1, y_.shape[0], 1)\n",
    "        verbose = 2 if (i % 15 == 0) else 0 # print only 1/25th of the time\n",
    "        model.fit(X_, [y_1, y_2], epochs=1, shuffle=False, batch_size=1, verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflowjs as tfjs\n",
    "tfjs.converters.save_keras_model(model, 'Full-Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf static/Full-Model\n",
    "mv Full-Model static/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
